{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chainer\n",
    "from chainer import cuda, Function, gradient_check, report, training, utils, Variable\n",
    "from chainer import datasets, iterators, optimizers, serializers\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.training import extensions\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import time\n",
    "from IPython.display import HTML\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation Lab 2:  Neural Language Modeling\n",
    "\n",
    "In this lab, we will train recurrent neural network character level language models. We will be experimenting with model architecture and we'll try modellig two different languages. The task of a language model is to predict the next token, given the history of observed tokens. We will be evaluating our models directly against this objective by measuring perplexity. We will also use the models to generate new text so that we can jusge how well ware the characteristics of the languages and the particular datasets captured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chainer\n",
    "\n",
    "Try and work through the basic [chainer tutorial](http://docs.chainer.org/en/stable/tutorial/basic.html). You can skip *advanced* chainer concepts such as the [trainer class](http://docs.chainer.org/en/stable/tutorial/basic.html#trainer)\n",
    "\n",
    "Finally, have a look at the multi-layer feedforward neural network [example on MNIST dataset](http://docs.chainer.org/en/stable/tutorial/basic.html#example-multi-layer-perceptron-on-mnist). The code for ```class MLP(Chain)``` definition shows how we can add [layers](http://docs.chainer.org/en/stable/reference/links.html#learnable-connections) (linear in this example, other choices include LTSM, GRU) and [activation functions](http://docs.chainer.org/en/stable/reference/functions.html#activation-functions) (RELU in this example, other choices include sigmoid, tanh ) in Chainer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background material\n",
    "This lab is based on text and code from several online resources. It is highly recommended to check out the following:\n",
    "- A great explanation and visualization of recurrent neural networks: [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "- [numpy based code to train a character-level language model](https://gist.github.com/karpathy/d4dee566867f8291f086)\n",
    "- [Chainer implementation of the above source code](https://github.com/yusuketomoto/chainer-char-rnn)\n",
    "- [Chainer reference](http://docs.chainer.org/en/stable/reference/)\n",
    "- [Really cool explanation of LSTM (and GRU)](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Datasets\n",
    "---\n",
    "We will be using two datasets:\n",
    "* English: collection of all William Shakespeare's work, *tinyshakespeare* (created by Andrej Karpathy: https://github.com/karpathy/char-rnn/tree/master/data/tinyshakespeare) \n",
    "* Polish: the epic poem *Pan Tadeusz* by Adam Mickiewicz\n",
    "\n",
    "The input files can be found in the ```data/``` directory.\n",
    "\n",
    "Let's look at the first few lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Shakespeare -------------\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "---------------------------------------\n",
      "\n",
      "------------- Polish -------------\n",
      "Adam Mickiewicz\n",
      "\n",
      "Pan Tadeusz czyli ostatni zajazd na Litwie\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Księga pierwsza\n",
      "\n",
      "\n",
      "\n",
      "Gospodarstwo\n",
      "\n",
      "Powrót panicza — Spotkanie się pierwsze w pokoiku, drugie u stołu — Ważna Sędziego nauka o grzeczności — Podkomorzego uwagi polityczne nad modami — Początek sporu o Kusego i Sokoła — Żale Wojskiego — Ostatni Woźny Trybunału — Rzut oka na ówczesny stan polityczny Litwy i Europy\n",
      "\n",
      "    Litwo! Ojczyzno moja! ty jesteś jak zdrowie:\n",
      "Ile cię trzeba cenić, ten tylko się dowie,\n",
      "Kto cię stracił. Dziś piękność twą w całej ozdobie\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"------------- Shakespeare -------------\")\n",
    "!head -n 20 data/tinyshakespeare.txt\n",
    "print(\"---------------------------------------\")\n",
    "print(\"\\n------------- Polish -------------\")\n",
    "!head -n 20 data/mickiewicz.txt\n",
    "print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that both texts are **structured**. In case of Shakespeare's plays there are speaker tags, and new line characters after each dialog. In *Pan Tadeusz* the structure is less obvious, but more rigid, as each line (excluding chapter titles and chapter synopsis) is composed of exactly thirteen syllables. \n",
    "\n",
    "We do not perform any text preprocessing. That means that stopwords are not removed, capital letters are not converted to lower case and punctuation is left intact.\n",
    "\n",
    "As our models will be **predicting characters**, let's explore the number of unique characters and their frequencies.\n",
    "\n",
    "**TODO** add a frequency histogram over the whole character vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prune_data_for_debugging = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the training file location\n",
    "English = False\n",
    "\n",
    "if English:\n",
    "    train_fname = os.path.join(\"data\", \"tinyshakespeare.txt\")\n",
    "    data_postfix = \"shakespeare\"\n",
    "else:\n",
    "    train_fname = os.path.join(\"data\", \"mickiewicz.txt\")\n",
    "    data_postfix = \"tadeusz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_input_txt(fname):\n",
    "    # define a dictionary. Each unique character will be a key in the dictionary\n",
    "    # and the value will be its count\n",
    "    chars = {}\n",
    "    with open(fname, \"r\") as f:\n",
    "        # read entire file content into buffer\n",
    "        if prune_data_for_debugging:\n",
    "            data = f.read()[:10000]\n",
    "        else:\n",
    "            data = f.read()\n",
    "    # count occurrences of each character\n",
    "    for c in data:\n",
    "        if c not in chars:\n",
    "            chars[c] = 1\n",
    "        else:\n",
    "            chars[c] += 1\n",
    "    return data, chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Polish corpus --------\n",
      "\n",
      "          data stats          \n",
      "          ----------          \n",
      "    total characters |      10000\n",
      "  total unique chars |         71\n",
      "    train characters |       9000\n",
      "     test characters |       1000\n",
      "\n",
      "   top 5 characters in data   \n",
      "   ------------------------   \n",
      "                char |       freq\n",
      "                     |       1368\n",
      "                   a |        694\n",
      "                   i |        688\n",
      "                   o |        610\n",
      "                   e |        581\n"
     ]
    }
   ],
   "source": [
    "data, chars = read_input_txt(train_fname)\n",
    "vocab_size = len(chars.keys())\n",
    "data_size = len(data)\n",
    "\n",
    "# 90%-10% split for test and validation data\n",
    "train_data = data[: data_size * 90 // 100]\n",
    "dev_data = data[data_size * 90 // 100 :]\n",
    "train_size = len(train_data)\n",
    "dev_size = len(dev_data)\n",
    "\n",
    "if English:\n",
    "    print(\"-------- English corpus --------\")\n",
    "else:\n",
    "    print(\"-------- Polish corpus --------\")\n",
    "print(\"\\n{0:^30}\".format(\"data stats\"))\n",
    "print(\"{0:^30}\".format(\"-\" * len(\"data stats\")))\n",
    "print(\"{0:>20s} | {1:10d}\".format(\"total characters\", data_size))\n",
    "print(\"{0:>20s} | {1:10d}\".format(\"total unique chars\", len(chars.keys())))\n",
    "print(\"{0:>20s} | {1:10d}\".format(\"train characters\", train_size))\n",
    "print(\"{0:>20s} | {1:10d}\".format(\"test characters\", dev_size))\n",
    "\n",
    "# printing top 5 characters based on frequency\n",
    "\n",
    "print(\"\\n{0:^30}\".format(\"top 5 characters in data\"))\n",
    "print(\"{0:^30}\".format(\"-\" * len(\"top 5 characters in data\")))\n",
    "print(\"{0:>20s} | {1:>10s}\".format(\"char\", \"freq\"))\n",
    "out_rows = [(k, v) for k, v in sorted(list(chars.items()), reverse=True, key=lambda t:t[1])[:5]]\n",
    "for k, v in out_rows:\n",
    "    print(\"{0:>20s} | {1:>10d}\".format(k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding data\n",
    "\n",
    "The minimal pre-processing of the dataset which we perform involves mapping each character to a unique integer id. It is done for the purposes of efficiency, as numerical ids are easier to manipulate than string ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****original text excerpt**** \n",
      "Adam Mickiewicz\n",
      "\n",
      "Pan Tadeusz czyli ostatni zajazd \n",
      "****text converted to integer representation**** \n",
      "01234567869106711121213214415219161711471118196420172122114641122221114\n"
     ]
    }
   ],
   "source": [
    "# prepare an integer representation of the dataset\n",
    "data_char_to_ids = []\n",
    "for c in data:\n",
    "    data_char_to_ids.append(char_to_ix[c])\n",
    "print(\"****original text excerpt**** \\n{0:s}\".format(data[:50]))\n",
    "print(\"****text converted to integer representation**** \\n{0:s}\".format(\"\".join(map(str, \n",
    "                                                                       data_char_to_ids[:50]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "------\n",
    "## Models\n",
    "------\n",
    "All our models will use the RNN base class, which is defined here. When you'll be asked to implement some changes to the model architecture, you should modify this class. It specifies how many layer will the network have, what their sizes will be, what sort of cells will be used and what is the loss function.\n",
    "\n",
    "Chainer reference can be found at: http://docs.chainer.org/en/stable/reference/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(Chain):\n",
    "    # constructor\n",
    "    # vocab_size: indicates the number of unique characters in the vocabulary\n",
    "    # n_units: size of the hidden layer\n",
    "    # gpu_id: if >=0, use GPU, else CPU\n",
    "    def __init__(self, vocab_size, n_units, gpu_id, use_LSTM=True):\n",
    "        # initialise Chainer base class\n",
    "        super(RNN, self).__init__()\n",
    "        #---------------------------------------------------------\n",
    "        # construct Neural Network\n",
    "        #---------------------------------------------------------\n",
    "        # add embedding layer\n",
    "        # http://docs.chainer.org/en/stable/reference/links.html#embedid\n",
    "        #---------------------------------------------------------\n",
    "        self.add_link(\"embed\", L.EmbedID(vocab_size, n_units))\n",
    "        #---------------------------------------------------------\n",
    "        # add LSTM or GRU layer\n",
    "        if use_LSTM:\n",
    "            # http://docs.chainer.org/en/stable/reference/links.html#lstm\n",
    "            self.add_link(\"L1\", L.LSTM(n_units, n_units))\n",
    "        else:\n",
    "            # http://docs.chainer.org/en/stable/reference/links.html#gru\n",
    "            self.add_link(\"L1\", L.StatefulGRU(n_units, n_units))\n",
    "        '''\n",
    "        ------------------------------------------------------------------\n",
    "        Q3 - ADD CODE (around) HERE\n",
    "        Go deep, add 1 more LSTM/GRU layer\n",
    "        ------------------------------------------------------------------\n",
    "        '''\n",
    "        #---------------------------------------------------------\n",
    "        # add output layer\n",
    "        # http://docs.chainer.org/en/stable/reference/links.html#linear\n",
    "        self.add_link(\"out\", L.Linear(n_units,vocab_size))\n",
    "        #---------------------------------------------------------\n",
    "        \n",
    "    def reset_state(self):\n",
    "        # reset LSTM state\n",
    "        # NOTE: the name field using during add_link call \n",
    "        # is used to refer to the layer\n",
    "        self.L1.reset_state()\n",
    "        \n",
    "    # function to compute the forward pass through the network layers\n",
    "    def forward(self, word):\n",
    "        # lookup character embedding and compute the hidden state\n",
    "        h1 = self.L1(self.embed(word))\n",
    "        # compute the output layer over the hidden state\n",
    "        out = self.out(h1)\n",
    "        return out\n",
    "    \n",
    "    # function to compute the loss for training\n",
    "    def __call__(self, c_n1, c_n2):\n",
    "        # call forward to predict output\n",
    "        # calculate softmax and then the cross entropy loss\n",
    "        # Chainer (and most NN frameworks) provide functions to compute \n",
    "        # the softmax and cross entropy loss together\n",
    "        self.loss = F.softmax_cross_entropy(self.forward(c_n1), c_n2)\n",
    "        # return loss\n",
    "        return self.loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify whether traing should be done on CPU or GPU. In this lab we will train on CPUs. If you wish to try GPU training on your own machine, follow GPU-specific Chainer installation instructions as given on the [webpage](http://docs.chainer.org/en/stable/install.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if >= 0, use GPU, if negative use CPU\n",
    "gpuid = -1\n",
    "\n",
    "# use cuda if GPU or numpy if CPU\n",
    "xp = cuda.cupy if gpuid >= 0 else np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some paramteres which need to be preset. We specify the optimizer we wish to use and the rate of weight decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_model(model):\n",
    "    #---------------------------------------------------------\n",
    "    # copy model to GPU if selected\n",
    "    #---------------------------------------------------------\n",
    "    if gpuid >= 0:\n",
    "        cuda.get_device(gpuid).use()\n",
    "        model.to_gpu()\n",
    "    #---------------------------------------------------------\n",
    "    # optimizer\n",
    "    # Select an optimizer\n",
    "    # http://docs.chainer.org/en/stable/reference/optimizers.html\n",
    "    # Alternatives: SGD, AdaGrad, RMSprop, etc\n",
    "    # We can also add weight decay\n",
    "    #---------------------------------------------------------\n",
    "    optimizer = optimizers.Adam()\n",
    "    # link optimizer to model\n",
    "    optimizer.setup(model)\n",
    "    # add weight decay\n",
    "    optimizer.add_hook(chainer.optimizer.WeightDecay(rate=0.0005))\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the base class we now define a particular model instance which we'll be training. To start with, we'll define a LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#---------------------------------------------------------\n",
    "# define model\n",
    "#---------------------------------------------------------\n",
    "use_LSTM = True\n",
    "lstm_postfix = \"lstm\" if use_LSTM else \"gru\"\n",
    "model_baseline = RNN(vocab_size, 50, gpuid, use_LSTM=use_LSTM)\n",
    "# the name field is used for logging stats and storing the model parameters\n",
    "model_baseline.__dict__['name'] = \"baseline_{0:s}_{1:s}\".format(data_postfix, lstm_postfix)\n",
    "'''\n",
    "------------------------------------------------------------------\n",
    "Q2 - ADD CODE (around) HERE\n",
    "\n",
    "A. Define a new model using GRU instead of LSTM\n",
    "B. Train and compute loss and perplexity as done for model_baseline\n",
    "C. Compare the performance and training time between the GRU and LSTMs\n",
    "------------------------------------------------------------------\n",
    "'''\n",
    "optimizer_baseline = setup_model(model_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log training progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to train a batch of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_batch(batch_data, model, optimizer):\n",
    "    # reset LSTM initial state before training each batch\n",
    "    model.reset_state()\n",
    "    \n",
    "    # reset loss\n",
    "    loss = 0\n",
    "    \n",
    "    # for each character in the batch, the target character is the next in sequence\n",
    "    for i, (curr_char, next_char) in enumerate(zip(batch_data, batch_data[1:]), start=1):\n",
    "        # convert curr char into a chainer variable\n",
    "        c1 = Variable(xp.asarray([curr_char], dtype=np.int32), volatile=False)\n",
    "        c2 = Variable(xp.asarray([next_char], dtype=np.int32), volatile=False)\n",
    "        # compute loss for each character and the prediction\n",
    "        loss += model(c1, c2)\n",
    "    \n",
    "    # reset model gradients\n",
    "    model.cleargrads()\n",
    "    # compute loss through back prop\n",
    "    loss.backward()\n",
    "    # update parameters\n",
    "    optimizer.update()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to sample from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text generation\n",
    "The above table shows that the \" \" (space/blank) character occurs most often. As we train our language model, will the model learn proper word boundaries? That is, can the model predict when to insert a space between sequences?\n",
    "\n",
    "We will answer this question using empirical observations by sampling our model to generate text.\n",
    "\n",
    "[Spoiler - Shakespeare generated by Karpathy's model](http://cs.stanford.edu/people/karpathy/char-rnn/shakespear.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(s_chars, n_chars, model):\n",
    "    # Sample n_chars, with starting char: s_char\n",
    "    sample_text = s_chars[:]\n",
    "    \n",
    "    model.reset_state()\n",
    "    \n",
    "    # initialize with s_char\n",
    "    for s_char in s_chars:\n",
    "        # compute the prediction from the starting character\n",
    "        c = Variable(xp.asarray([char_to_ix[s_char]], dtype=np.int32), volatile=True)\n",
    "        out = model.forward(c)\n",
    "\n",
    "    prob = F.softmax(out)\n",
    "    \n",
    "    # Sample remaining characters\n",
    "    for i in range(n_chars):\n",
    "        # compute probability distribution over the characters using softmax\n",
    "        prob = F.softmax(out)\n",
    "        \n",
    "        # if gpu, convert into numpy array in order to sample\n",
    "        if gpuid >= 0:\n",
    "            prob = cuda.to_cpu(prob.data)[0].astype(np.float64)\n",
    "        else:\n",
    "            prob = prob.data[0].astype(np.float64)\n",
    "        \n",
    "        # normalize probability\n",
    "        prob /= np.sum(prob)\n",
    "\n",
    "        # Sample next character from the predicted probability distribution\n",
    "        index = np.random.choice(range(len(prob)), p=prob)\n",
    "\n",
    "        # add sampled character to result\n",
    "        sample_text.append(ix_to_char[index])\n",
    "        \n",
    "        c = Variable(xp.asarray([index], dtype=np.int32), volatile=True)\n",
    "        # feed the character into the model\n",
    "        out = model.forward(c)\n",
    "        \n",
    "    # combine sampled text into a string\n",
    "    sampled_txt = ''.join(sample_text)\n",
    "    return sampled_txt, prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_loop(model, optimizer, data, n_epochs=3, batch_size=128, logging=True):\n",
    "    if logging and model.__dict__['name']:\n",
    "        train_log_fname = \"{0:s}_train.log\".format(model.__dict__['name'])\n",
    "        train_log = open(train_log_fname, \"w\")\n",
    "        train_writer = csv.writer(train_log, lineterminator=\"\\n\")\n",
    "        train_writer.writerow([\"iter\", \"loss\"])\n",
    "    \n",
    "    # compute the number of batches in the data\n",
    "    data_size = len(data)\n",
    "    num_batches = data_size // batch_size\n",
    "    \n",
    "    # print reference text excerpt\n",
    "    print(\"Reference text:\\n{0:s}\".format(data[1000:1100]))\n",
    "    # sample text from the model\n",
    "    # this is on the untrained model and the output will be random characters\n",
    "    print(\"Sampled text:\\n{0:s}\".format(sample(list(data[1000]), 100, model)[0]))\n",
    "    \n",
    "    # start training epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        # start progress bar for current epoch\n",
    "        sys.stderr.flush()\n",
    "        with tqdm(total=data_size) as pbar:\n",
    "            sys.stderr.flush()\n",
    "            for i in range(0, data_size, batch_size):\n",
    "                # loop through the entire data in chunks of batch_size\n",
    "                # note: using the integer id representation of the text\n",
    "                batch_data = data_char_to_ids[i:i+batch_size]\n",
    "                # call batch training\n",
    "                loss = train_batch(batch_data, model, optimizer)\n",
    "                # extract value of loss from Chainer variable returned\n",
    "                loss = float(loss.data)\n",
    "                # compute number of characters trained on so far\n",
    "                it = (epoch * data_size) + i + batch_size\n",
    "                # write loss to file\n",
    "                train_writer.writerow([it, loss])\n",
    "                '''\n",
    "                ------------------------------------------------------------------\n",
    "                Q1 - ADD CODE (around) HERE\n",
    "                \n",
    "                A. Compute perplexity and add this information to the train \n",
    "                log file\n",
    "                B. Compute perplixity over validation data and create a new log file\n",
    "                ------------------------------------------------------------------\n",
    "                '''\n",
    "                pbar.set_description(\"epoch={0:d}, loss={1:.6f}\".format(epoch+1, loss))\n",
    "                pbar.update(batch_size)\n",
    "                # Sample 10 times\n",
    "        # sample at the end of each epoch\n",
    "        print(\"Sampling from starting char={0:s}, {1:d} characters\".format(data[1000], 100))\n",
    "        print(\"Sampled text:\\n{0:s}\".format(sample(list(data[1000]), 100, model)[0]))\n",
    "    \n",
    "    if train_log:\n",
    "        train_log.close()\n",
    "        print(\"------------------------------------------------\")\n",
    "        print(\"train log file: {0:s}\".format(train_log_fname))\n",
    "    # Save model\n",
    "    if model.__dict__['name']:\n",
    "        serializers.save_npz(\"{0:s}.npz\".format(model.__dict__['name']), model)\n",
    "        print(\"------------------------------------------------\")\n",
    "        print(\"model file: {0:s}\".format(model.__dict__['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#---------------------------------------------------------\n",
    "# training batch size\n",
    "# compute loss for upto batch_size number of characters\n",
    "#---------------------------------------------------------\n",
    "batch_size = 128\n",
    "#---------------------------------------------------------\n",
    "# epochs\n",
    "# to stop training\n",
    "#--------------------------------------------------------- \n",
    "n_epochs = 1\n",
    "#---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/9000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference text:\n",
      "ch pagórków leśnych, do tych łąk zielonych,\n",
      "Szeroko nad błękitnym Niemnem rozciągnionych;\n",
      "Do tych pó\n",
      "Sampled text:\n",
      "cEgćIHthLóiźćHwMńu»czkk:EŚTm;żó:bŻNwDCyépgMwn;z?Drp?Z cękręźbijF mRT?ńŚAM… DtpóP Fj…!ŻL»lyn)uuźuś;G!(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=1, loss=410.642792: 9088it [00:14, 661.27it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling from starting char=c, 100 characters\n",
      "Sampled text:\n",
      "cuu ńGFd wirłiPdgłyze  cnciGoatnwmWeka.koiFoy\n",
      "aai wn ęejaiazd kiu oó bchDIaydo so d soN,łaaane  dwyda\n",
      "------------------------------------------------\n",
      "train log file: baseline_tadeusz_lstm_train.log\n",
      "------------------------------------------------\n",
      "model file: baseline_tadeusz_lstm\n"
     ]
    }
   ],
   "source": [
    "train_loop(model_baseline, optimizer_baseline,\n",
    "           train_data, n_epochs=n_epochs, \n",
    "           batch_size=batch_size, logging=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "model_fname = \"{0:s}.npz\".format(model_baseline.__dict__['name'])\n",
    "train_log_fname = \"{0:s}_train.log\".format(model_baseline.__dict__['name'])\n",
    "\n",
    "serializers.load_npz(model_fname, model_baseline)\n",
    "log_train = np.loadtxt(train_log_fname, delimiter=\",\", skiprows=True).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled text:\n",
      "kształt ogrodowych gloc Io,m o,Tnwe  py ie e\n",
      "dezis tmeż,yś \n",
      "a nnDziysncswysiois w ,na—, rnsz  «Chekrui mwn\n",
      "bł epKn gdpkz\n"
     ]
    }
   ],
   "source": [
    "print(\"Sampled text:\\n{0:s}\".format(sample(list(data[2000:2020]), 100, model_baseline)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAEYCAYAAACwWpkMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cb6b4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig1, ax1 = plt.subplots()\n",
    "ax1.plot(log_train[0], log_train[1])\n",
    "ax1.set_xlim(0, (n_epochs * train_size))\n",
    "ax1.set_xlabel(\"iteration\")\n",
    "ax1.set_ylabel(\"loss\", color=\"r\")\n",
    "for tlbl in ax1.get_yticklabels():\n",
    "    tlbl.set_color(\"r\")\n",
    "plt.legend(['training loss'], bbox_to_anchor=(1.48, 1.05), framealpha=0)\n",
    "plt.title(\"Training loss\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTIONS:\n",
    "\n",
    "For the questions which ask you to modify the code, please search for \"Q1\" or \"Q2\" in the code above for suggestions on where the modifications should be made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "    QUESTION 1 - evaluation using perplexity\n",
    "    \n",
    "                A. Compute perplexity and add this information to the train \n",
    "                   log file\n",
    "                B. Compute perplixity over validation data and create a new log file\n",
    "                \n",
    "    As you can see, we use cross-entropy loss to measure the total loss during the training phase.\n",
    "    Remind yourself what the relationship is between cross-entropy and perplexity.\n",
    "    Is the model trained to minimize perplexity of the training data? \n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "    QUESTION 2 - modify architecture\n",
    "    \n",
    "                A. Define a new model using GRU instead of LSTM\n",
    "                B. Train and compute loss and perplexity as done for model_baseline\n",
    "                C. Compare the performance and training time between the GRU and LSTMs\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "    QUESTION 3 - capuring morphological variants\n",
    "    \n",
    "                One of the benefits of recurrent neural networks for LM is that they are capable of\n",
    "                capturing long-range dependencies. A natural language phenomenon in which such\n",
    "                dependencies occur is morphological agreement. If a language requires that certain\n",
    "                elements of the sentence agree in a specific feature, the morphological variants\n",
    "                expressing that feature have to be used.\n",
    "                For example, English requires that verb and its subject agree for person. If the\n",
    "                subject is a 3rd person singular noun, the verb has to be inflected for the 3rd person:\n",
    "                    \"He buys some tangerines\" is ok while\n",
    "                    \"They buys some tngerines\" is ungrammatical.\n",
    "                \n",
    "                In this task you will inspect model performance on three agreement phenomena in Polish.\n",
    "                You will using the provided prompts as seeds for generation, and you'll check whether\n",
    "                the model predicts the next character right. For each prompt only one character is right,\n",
    "                i.e. the resulting word does not vialate agreement requirements. There are other characters\n",
    "                which produce a valid word, but the agreement is not maintained. Which character is right\n",
    "                is determined by the preceeding words.\n",
    "                \n",
    "                ***** Having inspected the Polish examples, create similar prompts for English (keep in mind that\n",
    "                we're modelling Shakespeare's English, so you might want to take a look at the corpus\n",
    "                before comming up with your prompts).\n",
    "                \n",
    "                Check whether your English models are more successful in predicting the right character\n",
    "                than the Polish models.\n",
    "                Why are you observing such results?\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------Sampled text-----------:\n",
      "Zosia ze wstążki kokardę zrobiłr\n",
      "Incorrect ...  (ಥ﹏ಥ)\n",
      "r\n",
      "\n",
      "------------Sampled text-----------:\n",
      "bocian ma skrzydła biał \n",
      "Incorrect ...  (ಥ﹏ಥ)\n",
      " \n",
      "\n",
      "------------Sampled text-----------:\n",
      "patrzyliśmy na piękną panns\n",
      "Incorrect ...  (ಥ﹏ಥ)\n",
      "s\n",
      " char | prob  \n",
      "      | 0.21678\n",
      "    a | 0.07987\n",
      "    i | 0.07255\n",
      "    e | 0.06124\n",
      "    o | 0.05899\n",
      "    z | 0.04155\n",
      "    c | 0.03309\n",
      "    y | 0.03031\n",
      "    d | 0.02990\n",
      "    s | 0.02529\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Q3\n",
    "'''\n",
    "\n",
    "if not English:\n",
    "    polish_samples = [\"Zosia ze wstążki kokardę zrobił\", \n",
    "                      \"bocian ma skrzydła biał\",\n",
    "                      \"patrzyliśmy na piękną pann\"]\n",
    "    \n",
    "    polish_right_answers = ['a', 'e', 'ę']\n",
    "    \n",
    "    polish_wrong_answers = [[' ', 'y', 'o'],\n",
    "                            ['a', 'y', 'o'],\n",
    "                            ['a', 'y', 'i', 'ą', 'o']]\n",
    "\n",
    "    s_ix = 1\n",
    "    model_sample_results = []\n",
    "\n",
    "    for i, s in enumerate(polish_samples):\n",
    "        model_sample_results.append(sample(list(polish_samples[i]), 1, model_baseline))\n",
    "        print(\"\\n------------Sampled text-----------:\\n{0:s}\".format(model_sample_results[i][0]))\n",
    "        if model_sample_results[i][0][-1] == polish_right_answers[i]:\n",
    "            print(\"Correct (▀̿Ĺ̯▀̿ ̿)\")\n",
    "        elif model_sample_results[i][0][-1] in polish_wrong_answers[i]:\n",
    "            print(\"In the ballpark ¯\\_(ツ)_/¯\")\n",
    "        else:\n",
    "            print(\"Incorrect ...  (ಥ﹏ಥ)\")\n",
    "\n",
    "    k = 10\n",
    "\n",
    "    top_k_ixs = np.argpartition(model_sample_results[s_ix][1], -k, axis=None)[-k:]\n",
    "    top_k_probs = model_sample_results[s_ix][1][np.argpartition(model_sample_results[s_ix][1], \n",
    "                                                           -k, axis=None)[-k:]]\n",
    "\n",
    "    print(\"{0:>5s} | {1:6s}\".format(\"char\", \"prob\"))\n",
    "    print(\"\\n\".join([\"{0:>5s} | {1:>.5f}\".format(c, p) \n",
    "                    for c, p in sorted(zip([ix_to_char[ix] for ix in top_k_ixs], top_k_probs), \n",
    "                                       reverse=True, key=lambda t: t[1])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "    EXTRA ACTIVITIES - what changes would help the model capture the structure of the data?\n",
    "    \n",
    "                A. Define a new model using GRU instead of LSTM\n",
    "                B. Train and compute loss and perplexity as done for model_baseline\n",
    "                C. Compare the performance and training time between the GRU and LSTMs\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## possible questions (in work)\n",
    "\n",
    "- What happens if we increase the batch size (or the training sequence)?\n",
    "- Modify the network to include more layers. Go deep vs go wide.\n",
    "- Back-propagation through Time? Why?\n",
    "- GRU vs LSTM?\n",
    "- Can we modify the code to a word level neural network model? This can also be an assignment question.\n",
    "- Plot embeddings over the words, or characters\n",
    "- Character level vs Word level RNN?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
